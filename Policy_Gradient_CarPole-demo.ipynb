{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cart Pole game\n",
    "# On-Policy Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment: OpenAi Gym \n",
    "\n",
    "https://openai.com/\n",
    "\n",
    "### Random action for the CartPole game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import time\n",
    "env = gym.make('CartPole-v0')\n",
    "for i_episode in range(3):\n",
    "    observation = env.reset()\n",
    "    for t in range(200):\n",
    "        env.render()\n",
    "        time.sleep(0.02)\n",
    "        print(observation)\n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        print(reward)\n",
    "#        if done:\n",
    "#            print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "#            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy Gradient method for playing Cart Pole game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loadding library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yanhua/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "#from RL_brain import PolicyGradient\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "#DISPLAY_REWARD_THRESHOLD = 400  # renders environment if total episode reward is greater then this threshold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "RENDER = False  # rendering wastes time\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "env.seed(1)     # reproducible, general Policy gradient has high variance\n",
    "env = env.unwrapped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CartPole environment information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(2)\n",
      "Box(4,)\n",
      "[4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38]\n",
      "[-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38]\n"
     ]
    }
   ],
   "source": [
    "print(env.action_space)\n",
    "print(env.observation_space)\n",
    "print(env.observation_space.high)\n",
    "print(env.observation_space.low)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Built neural network graph.\n",
    "\n",
    "### 2 dense layer neural network. output the probability of action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the network parameter\n",
    "output_graph=False\n",
    "learning_rate=0.01\n",
    "reward_decay=0.95\n",
    "    \n",
    "n_actions = env.action_space.n\n",
    "n_features = env.observation_space.shape[0]\n",
    "lr = learning_rate\n",
    "gamma = reward_decay\n",
    "\n",
    "ep_obs, ep_as, ep_rs = [], [], []\n",
    "\n",
    "with tf.name_scope('inputs'):\n",
    "        tf_obs = tf.placeholder(tf.float32, [None, n_features], name=\"observations\")\n",
    "        tf_acts = tf.placeholder(tf.int32, [None, ], name=\"actions_num\")\n",
    "        tf_vt = tf.placeholder(tf.float32, [None, ], name=\"actions_value\")\n",
    "    # fc1\n",
    "layer = tf.layers.dense(\n",
    "        inputs=tf_obs,\n",
    "        units=10,\n",
    "        activation=tf.nn.tanh,  # tanh activation\n",
    "        kernel_initializer=tf.random_normal_initializer(mean=0, stddev=0.3),\n",
    "        bias_initializer=tf.constant_initializer(0.1),\n",
    "        name='fc1'\n",
    "    )\n",
    "    # fc2\n",
    "all_act = tf.layers.dense(\n",
    "        inputs=layer,\n",
    "        units=n_actions,\n",
    "        activation=None,\n",
    "        kernel_initializer=tf.random_normal_initializer(mean=0, stddev=0.3),\n",
    "        bias_initializer=tf.constant_initializer(0.1),\n",
    "        name='fc2'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### output the approximate action for maximum reward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_act_prob = tf.nn.softmax(all_act, name='act_prob')  # use softmax to convert to probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The policy gradient method.\n",
    "\n",
    "### $log[\\pi(action|state)]*R(state,action)$\n",
    "\n",
    "## $W = W + LearningRate*log[\\pi(action|state)]*R(state,action)$\n",
    "https://www.sharelatex.com/learn/Mathematical_expressions\n",
    "\n",
    "http://web.ift.uib.no/Teori/KURS/WRK/TeX/symALL.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('loss'):\n",
    "    # to maximize total reward (log_p * R) is to minimize -(log_p * R), and the tf only have minimize(loss)\n",
    "    neg_log_prob = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=all_act, labels=tf_acts)   # this is negative log of chosen action\n",
    "        # or in this way:\n",
    "    # neg_log_prob = tf.reduce_sum(-tf.log(all_act_prob)*tf.one_hot(tf_acts, n_actions), axis=1)\n",
    "loss = tf.reduce_mean(neg_log_prob * tf_vt)  # reward guided loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the tensorflow graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('train'):\n",
    "    train_op = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "    \n",
    "sess = tf.Session()\n",
    "\n",
    "if output_graph:\n",
    "    # $ tensorboard --logdir=logs\n",
    "    # http://0.0.0.0:6006/\n",
    "    # tf.train.SummaryWriter soon be deprecated, use following\n",
    "    tf.summary.FileWriter(\"logs/\", sess.graph)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### choosing the action form the probability of action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_action(observation):\n",
    "    prob_weights = sess.run(all_act_prob, feed_dict={tf_obs: observation[np.newaxis, :]})\n",
    "    action = np.random.choice(range(prob_weights.shape[1]), p=prob_weights.ravel())  # select action w.r.t the actions prob\n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  store the data for training the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_transition(s, a, r):\n",
    "    ep_obs.append(s)\n",
    "    ep_as.append(a)\n",
    "    ep_rs.append(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play self for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_episodes=500 #game episodes setting for traning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the nueral network.\n",
    "training per one time game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0   reward: 14\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa02e38dda0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1   reward: 13\n",
      "episode: 2   reward: 14\n",
      "episode: 3   reward: 14\n",
      "episode: 4   reward: 14\n",
      "episode: 5   reward: 14\n",
      "episode: 6   reward: 14\n",
      "episode: 7   reward: 14\n",
      "episode: 8   reward: 14\n",
      "episode: 9   reward: 14\n",
      "episode: 10   reward: 14\n",
      "episode: 11   reward: 14\n",
      "episode: 12   reward: 14\n",
      "episode: 13   reward: 14\n",
      "episode: 14   reward: 15\n",
      "episode: 15   reward: 15\n",
      "episode: 16   reward: 15\n",
      "episode: 17   reward: 15\n",
      "episode: 18   reward: 15\n",
      "episode: 19   reward: 15\n",
      "episode: 20   reward: 15\n",
      "episode: 21   reward: 15\n",
      "episode: 22   reward: 15\n",
      "episode: 23   reward: 15\n",
      "episode: 24   reward: 15\n",
      "episode: 25   reward: 15\n",
      "episode: 26   reward: 15\n",
      "episode: 27   reward: 15\n",
      "episode: 28   reward: 15\n",
      "episode: 29   reward: 15\n",
      "episode: 30   reward: 16\n",
      "episode: 31   reward: 15\n",
      "episode: 32   reward: 16\n",
      "episode: 33   reward: 16\n",
      "episode: 34   reward: 16\n",
      "episode: 35   reward: 16\n",
      "episode: 36   reward: 16\n",
      "episode: 37   reward: 17\n",
      "episode: 38   reward: 17\n",
      "episode: 39   reward: 18\n",
      "episode: 40   reward: 18\n",
      "episode: 41   reward: 20\n",
      "episode: 42   reward: 20\n",
      "episode: 43   reward: 21\n",
      "episode: 44   reward: 21\n",
      "episode: 45   reward: 21\n",
      "episode: 46   reward: 21\n",
      "episode: 47   reward: 22\n",
      "episode: 48   reward: 22\n",
      "episode: 49   reward: 22\n",
      "episode: 50   reward: 24\n",
      "episode: 51   reward: 25\n",
      "episode: 52   reward: 25\n",
      "episode: 53   reward: 26\n",
      "episode: 54   reward: 26\n",
      "episode: 55   reward: 28\n",
      "episode: 56   reward: 28\n",
      "episode: 57   reward: 28\n",
      "episode: 58   reward: 28\n",
      "episode: 59   reward: 28\n",
      "episode: 60   reward: 29\n",
      "episode: 61   reward: 30\n",
      "episode: 62   reward: 30\n",
      "episode: 63   reward: 30\n",
      "episode: 64   reward: 30\n",
      "episode: 65   reward: 31\n",
      "episode: 66   reward: 31\n",
      "episode: 67   reward: 32\n",
      "episode: 68   reward: 32\n",
      "episode: 69   reward: 32\n",
      "episode: 70   reward: 33\n",
      "episode: 71   reward: 34\n",
      "episode: 72   reward: 35\n",
      "episode: 73   reward: 34\n",
      "episode: 74   reward: 35\n",
      "episode: 75   reward: 36\n",
      "episode: 76   reward: 37\n",
      "episode: 77   reward: 37\n",
      "episode: 78   reward: 39\n",
      "episode: 79   reward: 40\n",
      "episode: 80   reward: 41\n",
      "episode: 81   reward: 42\n",
      "episode: 82   reward: 43\n",
      "episode: 83   reward: 44\n",
      "episode: 84   reward: 46\n",
      "episode: 85   reward: 47\n",
      "episode: 86   reward: 51\n",
      "episode: 87   reward: 52\n",
      "episode: 88   reward: 53\n",
      "episode: 89   reward: 54\n",
      "episode: 90   reward: 57\n",
      "episode: 91   reward: 58\n",
      "episode: 92   reward: 58\n",
      "episode: 93   reward: 61\n",
      "episode: 94   reward: 61\n",
      "episode: 95   reward: 63\n",
      "episode: 96   reward: 64\n",
      "episode: 97   reward: 72\n",
      "episode: 98   reward: 76\n",
      "episode: 99   reward: 77\n",
      "episode: 100   reward: 83\n",
      "episode: 101   reward: 88\n",
      "episode: 102   reward: 90\n",
      "episode: 103   reward: 91\n",
      "episode: 104   reward: 91\n",
      "episode: 105   reward: 92\n",
      "episode: 106   reward: 94\n",
      "episode: 107   reward: 96\n",
      "episode: 108   reward: 97\n",
      "episode: 109   reward: 100\n",
      "episode: 110   reward: 101\n",
      "episode: 111   reward: 102\n",
      "episode: 112   reward: 102\n",
      "episode: 113   reward: 103\n",
      "episode: 114   reward: 104\n",
      "episode: 115   reward: 105\n",
      "episode: 116   reward: 105\n",
      "episode: 117   reward: 107\n",
      "episode: 118   reward: 107\n",
      "episode: 119   reward: 108\n",
      "episode: 120   reward: 108\n",
      "episode: 121   reward: 109\n",
      "episode: 122   reward: 109\n",
      "episode: 123   reward: 112\n",
      "episode: 124   reward: 111\n",
      "episode: 125   reward: 112\n",
      "episode: 126   reward: 114\n",
      "episode: 127   reward: 114\n",
      "episode: 128   reward: 114\n",
      "episode: 129   reward: 115\n",
      "episode: 130   reward: 115\n",
      "episode: 131   reward: 115\n",
      "episode: 132   reward: 116\n",
      "episode: 133   reward: 118\n",
      "episode: 134   reward: 118\n",
      "episode: 135   reward: 118\n",
      "episode: 136   reward: 118\n",
      "episode: 137   reward: 118\n",
      "episode: 138   reward: 119\n",
      "episode: 139   reward: 120\n",
      "episode: 140   reward: 120\n",
      "episode: 141   reward: 122\n",
      "episode: 142   reward: 123\n",
      "episode: 143   reward: 123\n",
      "episode: 144   reward: 123\n",
      "episode: 145   reward: 124\n",
      "episode: 146   reward: 127\n",
      "episode: 147   reward: 127\n",
      "episode: 148   reward: 133\n",
      "episode: 149   reward: 136\n",
      "episode: 150   reward: 153\n",
      "episode: 151   reward: 158\n",
      "episode: 152   reward: 176\n",
      "episode: 153   reward: 176\n",
      "episode: 154   reward: 176\n",
      "episode: 155   reward: 179\n",
      "episode: 156   reward: 181\n",
      "episode: 157   reward: 188\n",
      "episode: 158   reward: 199\n",
      "episode: 159   reward: 204\n",
      "episode: 160   reward: 223\n",
      "episode: 161   reward: 238\n",
      "episode: 162   reward: 241\n",
      "episode: 163   reward: 243\n",
      "episode: 164   reward: 245\n",
      "episode: 165   reward: 247\n",
      "episode: 166   reward: 260\n",
      "episode: 167   reward: 271\n",
      "episode: 168   reward: 275\n",
      "episode: 169   reward: 277\n",
      "episode: 170   reward: 278\n",
      "episode: 171   reward: 280\n",
      "episode: 172   reward: 286\n",
      "episode: 173   reward: 286\n",
      "episode: 174   reward: 286\n",
      "episode: 175   reward: 308\n",
      "episode: 176   reward: 329\n",
      "episode: 177   reward: 334\n",
      "episode: 178   reward: 353\n",
      "episode: 179   reward: 410\n",
      "episode: 180   reward: 413\n",
      "episode: 181   reward: 447\n",
      "episode: 182   reward: 513\n",
      "episode: 183   reward: 555\n",
      "episode: 184   reward: 553\n",
      "episode: 185   reward: 619\n",
      "episode: 186   reward: 620\n",
      "episode: 187   reward: 726\n",
      "episode: 188   reward: 750\n",
      "episode: 189   reward: 852\n",
      "episode: 190   reward: 873\n",
      "episode: 191   reward: 934\n",
      "episode: 192   reward: 977\n",
      "episode: 193   reward: 982\n",
      "episode: 194   reward: 1326\n",
      "episode: 195   reward: 1323\n",
      "episode: 196   reward: 1434\n",
      "episode: 197   reward: 1430\n",
      "episode: 198   reward: 1754\n",
      "episode: 199   reward: 1756\n",
      "episode: 200   reward: 1827\n",
      "episode: 201   reward: 2112\n"
     ]
    }
   ],
   "source": [
    "for i_episode in range(game_episodes):\n",
    "\n",
    "    observation = env.reset()\n",
    "\n",
    "    while True:\n",
    "        if RENDER: env.render()\n",
    "\n",
    "        action = choose_action(observation)\n",
    "\n",
    "        observation_, reward, done, info = env.step(action)\n",
    "\n",
    "        store_transition(observation, action, reward)\n",
    "\n",
    "        if done:\n",
    "            ep_rs_sum = sum(ep_rs)\n",
    "\n",
    "            if 'running_reward' not in globals():\n",
    "                running_reward = ep_rs_sum\n",
    "            else:\n",
    "                running_reward = running_reward * 0.99 + ep_rs_sum * 0.01\n",
    "            #if running_reward > DISPLAY_REWARD_THRESHOLD: RENDER = True     # rendering\n",
    "            print(\"episode:\", i_episode, \"  reward:\", int(running_reward))\n",
    "\n",
    "            # discount and normalize episode reward\n",
    "            # discount episode rewards\n",
    "            discounted_ep_rs = np.zeros_like(ep_rs)\n",
    "            running_add = 0\n",
    "            for t in reversed(range(0, len(ep_rs))):\n",
    "                running_add = running_add * gamma + ep_rs[t]\n",
    "                discounted_ep_rs[t] = running_add\n",
    "\n",
    "            # normalize episode rewards\n",
    "            discounted_ep_rs -= np.mean(discounted_ep_rs)\n",
    "            discounted_ep_rs /= np.std(discounted_ep_rs)\n",
    "     \n",
    "            discounted_ep_rs_norm = discounted_ep_rs\n",
    "\n",
    "            # train on episode\n",
    "            sess.run(train_op, feed_dict={\n",
    "                tf_obs: np.vstack(ep_obs),  # shape=[None, n_obs]\n",
    "                tf_acts: np.array(ep_as),  # shape=[None, ]\n",
    "                tf_vt: discounted_ep_rs_norm,  # shape=[None, ]\n",
    "            })\n",
    "\n",
    "            ep_obs, ep_as, ep_rs = [], [], []    # empty episode data\n",
    "     \n",
    "            vt = discounted_ep_rs_norm\n",
    "\n",
    "            if i_episode == 0:\n",
    "                plt.plot(vt)    # plot the episode vt\n",
    "                plt.xlabel('episode steps')\n",
    "                plt.ylabel('normalized state-action value')\n",
    "                plt.show()\n",
    "            break\n",
    "\n",
    "        observation = observation_\n",
    "    if int(running_reward)>2000:\n",
    "        #3000\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wait a moment... ...\n",
    "\n",
    "# What is Reinforcement Learning\n",
    "\n",
    "The processing is Random action start -> Learning from self training and got error (reward) in environment -> Become Master\n",
    "\n",
    "Reinforcement Learning is the method of Learning from self-training error (reward) .\n",
    "\n",
    "RL used case: DeepMind AlphaGo (Model based RL) , Human behavior Robot . Self-driving car\n",
    "\n",
    "RL not use loss. RL use the reward.  For training the neural network.\n",
    "\n",
    "Some methods in Reinforcement Learning\n",
    "\n",
    "    1,valuable base: Q-learning, Sarsa\n",
    "    2,action base: Policy Gradients **\n",
    "    3,model base: Model based RL (know the environment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Policy Gradient\n",
    "\n",
    "action base\n",
    "\n",
    "output is probability of choosing action.\n",
    "\n",
    "use the reward to change the probability high or low for the action.\n",
    "\n",
    "and traing the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the traned neural network for checking performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_episode in range(1):\n",
    "\n",
    "    observation = env.reset()\n",
    "\n",
    "    while True:\n",
    "        if RENDER: env.render()\n",
    "\n",
    "        action = choose_action(observation)\n",
    "\n",
    "        observation_, reward, done, info = env.step(action)\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "        observation = observation_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "RENDER = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_episodes=1 #game episodes setting for traning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0   reward: 2315\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa02e55ac18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i_episode in range(game_episodes):\n",
    "\n",
    "    observation = env.reset()\n",
    "\n",
    "    while True:\n",
    "        if RENDER: env.render()\n",
    "\n",
    "        action = choose_action(observation)\n",
    "\n",
    "        observation_, reward, done, info = env.step(action)\n",
    "\n",
    "        store_transition(observation, action, reward)\n",
    "\n",
    "        if done:\n",
    "            ep_rs_sum = sum(ep_rs)\n",
    "\n",
    "            if 'running_reward' not in globals():\n",
    "                running_reward = ep_rs_sum\n",
    "            else:\n",
    "                running_reward = running_reward * 0.99 + ep_rs_sum * 0.01\n",
    "            #if running_reward > DISPLAY_REWARD_THRESHOLD: RENDER = True     # rendering\n",
    "            print(\"episode:\", i_episode, \"  reward:\", int(running_reward))\n",
    "\n",
    "            # discount and normalize episode reward\n",
    "            # discount episode rewards\n",
    "            discounted_ep_rs = np.zeros_like(ep_rs)\n",
    "            running_add = 0\n",
    "            for t in reversed(range(0, len(ep_rs))):\n",
    "                running_add = running_add * gamma + ep_rs[t]\n",
    "                discounted_ep_rs[t] = running_add\n",
    "\n",
    "            # normalize episode rewards\n",
    "            discounted_ep_rs -= np.mean(discounted_ep_rs)\n",
    "            discounted_ep_rs /= np.std(discounted_ep_rs)\n",
    "     \n",
    "            discounted_ep_rs_norm = discounted_ep_rs\n",
    "\n",
    "            ep_obs, ep_as, ep_rs = [], [], []    # empty episode data\n",
    "     \n",
    "            vt = discounted_ep_rs_norm\n",
    "\n",
    "            if i_episode == 0:\n",
    "                plt.plot(vt)    # plot the episode vt\n",
    "                plt.xlabel('episode steps')\n",
    "                plt.ylabel('normalized state-action value')\n",
    "                plt.show()\n",
    "            break\n",
    "\n",
    "        observation = observation_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store the neural network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in path: /home/yanhua/Documents/jupyter/yan/demo/save_model/PG_CartPole/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "#saver_path = saver.save(sess,\"/home/yanhua/Documents/jupyter/yan/demo/save_model/PG_CartPole/model.ckpt\")\n",
    "#print(\"Model saved in path: %s\" % saver_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/yanhua/Documents/jupyter/yan/demo/save_model/PG_CartPole/model.ckpt\n",
      "Model restored.\n"
     ]
    }
   ],
   "source": [
    "saver.restore(sess,\"/home/yanhua/Documents/jupyter/yan/demo/save_model/PG_CartPole/model.ckpt\")\n",
    "print(\"Model restored.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "RENDER = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_episode in range(1):\n",
    "\n",
    "    observation = env.reset()\n",
    "\n",
    "    while True:\n",
    "        if RENDER: env.render()\n",
    "\n",
    "        action = choose_action(observation)\n",
    "\n",
    "        observation_, reward, done, info = env.step(action)\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "        observation = observation_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# initializer the neural network for random action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for i_episode in range(3):\n",
    "\n",
    "    observation = env.reset()\n",
    "\n",
    "    for t in range(200):\n",
    "        env.render()\n",
    "        time.sleep(0.02)\n",
    "        action = choose_action(observation)\n",
    "        observation_, reward, done, info = env.step(action)\n",
    "        observation = observation_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "jupyter is just for understanding scenario.\n",
    "\n",
    "for real developing :\n",
    "env, method (A3C,PG,DDPG,Q-learning,... etc) ---> at least we can design two oriented object for the Reinforcement Learning.\n",
    "main programing---> Reinforcement Learning task scenario.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
